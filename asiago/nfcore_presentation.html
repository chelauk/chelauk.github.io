<!DOCTYPE html>
<html>
  <head>
    <title>Accelerator Asiago</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .column:first-of-type {float:left}
      .column:last-of-type {float:right}

      .split-40 .column:first-of-type {width: 40%}
      .split-40 .column:last-of-type {width: 60%}
      .image-33 img {width: 33%}
      .image-50 img {width: 50%}
      .image-75 img {width: 75%}
      .image-80 img {width: 80%}
      .image-90 img {width: 90%}
      .image-100 img {width: 100%}

    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

# Asiago Accelerator

---

class: split-40

.column[
# Pipelines
* Pipelines are an essential part of processing biological data.
* raw data is run through a series of pieces of software.
* each piece of software has settings options and requirements.
]


.column[![Right-aligned image](./images/pipeline.png)]

---

# There is a lot of workflow software available
.image-100[![image](./images/pipelines.png)]

---

# nextflow
a commonly used workflow organiser which has several advantages.

The central principle of nextflow is that an *input* which can variable representing say a file goes into a named `process`
which then produces an *output* which may be used by a further `process` down the line


```nextflow
process INDEX {
    input:
      path transcriptome 
    output:
      path 'index' 
    script:
      """
      salmon index --threads $task.cpus -t $transcriptome -i index
      """
  }
```

---
# nextflow
within the nextflow system these processes can easily be organised
### workflows

```javascript
include { INDEX; FASTQC; QUANT; MULTIQC } from './some/module/script.nf' 

read_pairs_ch = channel.fromFilePairs( params.reads)

workflow {
* INDEX( params.transcriptome )
  FASTQC( read_pairs_ch )
  QUANT( INDEX.out, read_pairs_ch )
  MULTIQC( QUANT.out.mix(FASTQC.out).collect(), multiqc_file )
}
```

---

### and subworkflows
```nextflow
workflow RNASEQ {
    take:
      transcriptome
      read_pairs_ch
   
    main: 
      INDEX(transcriptome)
      FASTQC(read_pairs_ch)
      QUANT(INDEX.out, read_pairs_ch)
  
    emit: 
       QUANT.out.mix(FASTQC.out).collect()
  }
```

---

.image-100[![Centre-aligned image](./images/nfcore.png)]
### 53 pipelines and counting


---

.image-33[![Centre-aligned image](./images/sarek_workflow.png)]
```R
nextflow run sarek -profile singularity
```


---

want to build your own pipeline?

```groovy
nf-core tools create
```
add modules into the pipeline?
```groovy
nf-core tools module insert
```


---

# arguments and flags.

* necessary/optional flags

```groovy
process FASTQTOBAM {
    fgbio --tmp-dir=tmpFolder \\
      FastqToBam \\
      -i read1_fastq.gz read2_fastq.gz \\
      -o sampleID_umi_converted.bam" \\
*     --read-structures "+T 12M11S+T" \\
*     --sample "sampleID" \\
*     --library "sampleID"
```


---
modules.config

```groovy
'markduplicates' {
  args             = "ASSUME_SORTED=true"
  publish_dir      = "preprocessing"
  publish_dir2     = "reports"
  publish_files    = [ 'md.bam'  : 'mark_duplicates' ]
  publish_files2   = [ 'metrics' : 'mark_duplicates_metrics']
}
```
---

```groovy
include { UMI_QC }       from './modules/local/subworkflow/umi_qc/umi_qc'                addParams(
    fastqc_options:                       modules['fastqc'],
    multiqc_options:                      modules['multiqc']
)```

---

# software

installing software is often a nightmare because of dependencies and permissions

* nf-core solves that by using self contained systems like docker and singularity

These are automatically downloaded and utilised when you run the pipeline.
The docker/singularity images match those environments available on conda.
https://depot.galaxyproject.org/singularity/

---


.image-100[![Centre-aligned image](./images/schema.png)]


---

### logging and monitoring

.image-100[![Centre-aligned image](./images/tower1.png)]


---

### logging and monitoring

.image-100[![Centre-aligned image](./images/tower2.png)]

---

.image-100[![Centre-aligned image](./images/manager.png)]

---

class: center, middle

# thanks!



    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
          highlightLanguage: 'groovy',
          highlightStyle: 'default',
          highlightLines: true,
      })
    </script>
  </body>
</html>

var slideshow = remark.create(
});
